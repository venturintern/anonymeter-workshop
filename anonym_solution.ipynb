{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "134117d5-795a-4174-a480-7ce5bf18d304",
   "metadata": {
    "id": "134117d5-795a-4174-a480-7ce5bf18d304",
    "tags": []
   },
   "source": [
    "# Workshop: Synthetic Data Evaluation with Anonymeter üõ°Ô∏è\n",
    "\n",
    "In today's data-driven landscape, the significance of synthetic data and anonymization techniques is undeniable. With the growing reliance on **Machine Learning (ML)** and **Deep Learning (DL)**, there's often a shortfall in accessible real-world data. **Synthetic Data Generation (SDG)** steps in to bridge this gap, allowing us to generate representative datasets for training models and for statistics insights. Moreover, while certain data might be available, it may not be public-ready due to its sensitive nature, limiting its utility when it comes to Data Science. Consider the vast realm of medical data: rife with sensitive information, yet essential for groundbreaking research.\n",
    "\n",
    "## Evaluating Synthetic Data: A Multifaceted Challenge üéØüîç\n",
    "\n",
    "Assessing the quality and efficacy of synthetic datasets is far from straightforward. At its core, the evaluation process hinges on two primary pillars: **utility** (the dataset's ability to serve its intended purpose effectively) and **privacy**. While striving for high utility, it's imperative to strike a balance. Hence, there's an inherent trade-off between utility and privacy. While ensuring high utility is paramount, maintaining privacy is non-negotiable. \n",
    "\n",
    "In essence, the challenge lies in creating synthetic datasets that not only mirror real-world data distributions but also uphold stringent privacy standards.\n",
    "\n",
    "## Turning Privacy Laws into Code: How Anonymeter Makes Legal Jargon Speak Tech üèõÔ∏è‚û°Ô∏èüíª\n",
    "Assessing whether a synthetic dataset adheres to the stringent privacy constraints is no trivial task. While concepts like **Differential Privacy** provide a mathematical foundation for privacy assurance, they often lack intuitive interpretability. The true complexity emerges when attempting to convey these nuanced privacy assurances to non-technical people (lawyers, stakeholders, business leaders). Often, there's a palpable disconnect between the intricate world of data science and the broader understanding of privacy.\n",
    "\n",
    "`Anonymeter` endeavors to translate the abstract notions of privacy assurance into tangible evaluations. Leveraging the tenets of the General Data Protection Regulation (**GDPR**), Anonymeter translates into code specific risks, such as ***Singling-Out***, ***Linkability*** and ***Inference***.\n",
    "\n",
    "### Guidelines for the workshop\n",
    "\n",
    "For this workshop, we will be exploiting the well-structured [Anonymeter GitHub repository](https://github.com/statice/anonymeter), by Anonos. This is the official open source code coupled with paper [\"A Unified Framework for Quantifying Privacy Risk in Synthetic Data\"](https://arxiv.org/abs/2211.10459).\n",
    "\n",
    "To easily access and integrate this code, you can install the `anonymeter` package using the command\n",
    "```bash\n",
    " pip install anonymeter\n",
    "```\n",
    "\n",
    "Moreover:\n",
    "- We recommend that you complete this workshop using Colab, you can use your favorite notebook environment if you wish, but we won't be able to help with errors due to environment settings\n",
    "- You will have sections marked **TO DO** that contain comments `#TODO` for you to fill in. You will be given time to complete the sections and we will discuss together. The instructions will be explained before each exercise.\n",
    "- At any given moment, you can ask questions. **Please interreupt the speaker if you are unable to run the notebook**. You can also use the chat to ask questions and we will read the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a259e7-4a6d-40c9-8c8d-6f69f51b07e6",
   "metadata": {
    "id": "a1a259e7-4a6d-40c9-8c8d-6f69f51b07e6"
   },
   "source": [
    "**!!! SKIP IF ALREADY EXECUTED !!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca6736-8600-4f04-a1db-260c5a28f64b",
   "metadata": {
    "collapsed": true,
    "id": "91ca6736-8600-4f04-a1db-260c5a28f64b",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib==3.8.0\n",
    "!pip install seaborn==0.13.0\n",
    "!pip install numpy==1.23.5\n",
    "!pip install pandas==1.5.3\n",
    "!pip install anonymeter==0.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a8c5e-90fc-4d79-b855-433354a5068b",
   "metadata": {
    "id": "1f7a8c5e-90fc-4d79-b855-433354a5068b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b5c1b-609e-485a-81a9-71bbed5aad8f",
   "metadata": {
    "id": "226b5c1b-609e-485a-81a9-71bbed5aad8f"
   },
   "source": [
    "## Load and visualize the dataset üìä\n",
    "\n",
    "The dataset is the [FIFA22 complete player dataset](https://www.kaggle.com/datasets/stefanoleone992/fifa-22-complete-player-dataset), publicly available on Kaggle. This dataset provides a detailed overview of football players stats, nationality, physical attributes, and age. In addition it shows aspects that would be deemed sensitive and private in a typical context, such as **annual wage**. \n",
    "\n",
    "By utilizing this dataset, we can effectively evaluate potential privacy leakages and understand the intricacies of data protection in real-world scenarios.\n",
    "\n",
    "The initial dataset is made up of 110 features, from which we selected only 8, willingly excluding the most private attribute: the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db71fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/venturintern/anonymeter-workshop/main/fifa.csv'\n",
    "df_name = pd.read_csv(path)\n",
    "df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_name.drop('short_name', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca059a26-64af-4004-8855-f3f8d533eec8",
   "metadata": {
    "id": "ca059a26-64af-4004-8855-f3f8d533eec8"
   },
   "source": [
    "### Display the dataset using seaborn.pairplot()\n",
    "**TO DO:** Let's modify the variable `hue` to visualize data's dependence on the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2891c62-637a-402c-807a-a722a0d167d6",
   "metadata": {
    "id": "d2891c62-637a-402c-807a-a722a0d167d6"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data=df, hue='position')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d274e-2b42-4a51-b64f-cc6a85a5c643",
   "metadata": {
    "id": "262d274e-2b42-4a51-b64f-cc6a85a5c643"
   },
   "source": [
    "## Synthetic Datasets\n",
    "\n",
    "We will work with synthetic datasets generated using three prominent libraries in the field:\n",
    "\n",
    "1. **[SDV (Synthetic Data Vault)](https://github.com/sdv-dev)**: A leading open-source library for synthetic data generation. This library provides, among others, the `GaussianCopula` and `CTGAN` model.\n",
    " \n",
    "2. **[SynthCity](https://github.com/vanderschaarlab/synthcity)**: This library enabled the implementation of `PrivBayes`, a well-known model for synthetic data generation exploiting Bayesian Networks and Causal Inference.\n",
    "\n",
    "3. **[SmartNoise](https://github.com/opendp/smartnoise-sdk)**: This tool applies Differential Privacy to SDV's most famous model, CTGAN, transforming it into `DPCTGAN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808c75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dpctgan = pd.read_csv('https://raw.githubusercontent.com/venturintern/anonymeter-workshop/main/DPCTGAN_15000.csv')\n",
    "df_privbayes = pd.read_csv('https://raw.githubusercontent.com/venturintern/anonymeter-workshop/main/privbayes_15000.csv')\n",
    "\n",
    "df_gaussian = pd.read_csv('https://raw.githubusercontent.com/venturintern/anonymeter-workshop/main/GaussianCopula_15000.csv')\n",
    "df_ctgan = pd.read_csv('https://raw.githubusercontent.com/venturintern/anonymeter-workshop/main/CTGAN_15000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b99611f",
   "metadata": {},
   "source": [
    "## Synthetic Data Evaluation: `ANONYMETER`\n",
    "\n",
    "`Anonymeter` contains privacy evaluators which measures the risks of ***Singling Out***, ***Linkability***, and ***Inference*** for a synthetic dataset. These risks are the three key indicators of factual anonymization according to the **European General Data Protection Regulation (GDPR)**.\n",
    " \n",
    "For each of these privacy risks, `anonymeter` provides an `Evaluator` class: `SinglingOutEvaluator`, `LinkabilityEvaluator`, and `InferenceEvaluator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9548738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anonymeter.evaluators import SinglingOutEvaluator, LinkabilityEvaluator, InferenceEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540164e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTION\n",
    "\n",
    "def print_results(results):\n",
    "\n",
    "    print(\"Number of attacks:\", results.n_attacks)\n",
    "    print('\\n')\n",
    "\n",
    "    print(\"Number of successes for main attacks:\", results.n_success)\n",
    "    print(\"Successs rate of main attack:\", results.attack_rate)\n",
    "    print(\"Risk linked to the main attack: \", results.risk(baseline=False))\n",
    "    print('\\n')\n",
    "\n",
    "    print(\"Number of successes for control attacks:\", results.n_control)\n",
    "    print(\"Successs rate of control attack:\", results.control_rate)\n",
    "    print('\\n')\n",
    "\n",
    "    print(\"Number of successes for baseline attacks:\", results.n_baseline)\n",
    "    print(\"Successs rate of baseline attack:\", results.baseline_rate)\n",
    "    print(\"Risk linked to the baseline attack: \", results.risk(baseline=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a086bec",
   "metadata": {},
   "source": [
    "To instantiate the evaluator you have to provide three dataframes: the original dataset `ori` which has been used to generate the synthetic data, the synthetic data `syn`, and a `control` dataset containing original records which have not been used to generate the synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467f00fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori = df.iloc[:15000, :]\n",
    "control = df.iloc[15000:, :]\n",
    "\n",
    "# Choose the synthetic dataset you want to test\n",
    "syn = df_privbayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505296f0",
   "metadata": {},
   "source": [
    "Another parameter common to all evaluators is the number of target records to attack (`n_attacks`).\n",
    "\n",
    "Important distinction:\n",
    "- **Generic information**: This is what an attacker can learn at a *population level*, it is what provides **utility** to the anonymized data\n",
    "- **Specific information**: This is what an attacker can learn at an *individual level*, it enables the attacker to breach the **privacy**. \n",
    "\n",
    "To distinguish these two levels of information in a synthetic dataset, `anonymeter` runs three different attacks:\n",
    "- the **main** privacy attack, in which the attacker uses the synthetic data to guess information on records in the original data. This attack should outperform random guessing in order for the results to be trusted. \n",
    "- the **control** privacy attack, in which the attacker uses the synthetic data to guess information on records in the control dataset. This attack is used to separate what the attacker learns from the utility of the synthetic data, and what is instead indication of privacy leaks.\n",
    "- the **baseline** attack, which models a naive attacker who ignores the synthetic data and guess randomly. This attack is a sanity check.\n",
    "\n",
    "Checking how many of these guesses are correct, the success rates of the different attacks are measured and used to derive an estimate of the privacy risk. \n",
    "\n",
    "<img src=\"./anonymeter_diagram.png\" width=\"900\" height=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2346c043",
   "metadata": {},
   "source": [
    "## `Singling Out Risk` ü´µüèΩ\n",
    "\n",
    "Singling out happens whenever it is possible to deduce that within the original dataset there is a single data record with a unique combination of one or more given attributes.\n",
    "\n",
    "üö® It is important to note that singling out does not imply re-identification. Yet the ability to isolate an individual is often enough to exert control on that individual, or to mount other privacy attacks.\n",
    "\n",
    "üå≥ What happens under the hood? The attacks are translated into code as queries, crafted using the synthetic dataset. These queries are then tested against the original dataset for validation.\n",
    "\n",
    "1. **Queries Generation**:\n",
    "\n",
    "  - **Baseline Attack**:\n",
    "    - We randomly select a value from one (univariate) or more (multivariate) columns in the synthetic dataset.\n",
    "    - Constructs a query based on this value, choosing an operator randomly from `==`, `!=`, `>`, `<`, `>=`, `<=` (accordingly to the type of the feature).\n",
    "      As an example, we could have `position == GoalKeeper` or `age >= 29 AND club_name == Paris Saint Germain `\n",
    "  \n",
    "    Note: The number of queries generated isn't influenced by the synthetic dataset's characteristics since they're entirely random.\n",
    "\n",
    "  - **Main Attack & Control Attack**:\n",
    "   \n",
    "    *i) Univariate*: For each column `col` in the synthetic dataset:\n",
    "      - We check for a single `NaN` value and generate the query `col == NaN`.\n",
    "      - If the column is numerical: we create two queries `col < min` and `col > max`.\n",
    "      - We craft queries for rare values, i.e. values that appear only once in the column. Queries are generated as `col == rare_value` for each unique value.\n",
    "\n",
    "    *ii) Multivariate*: While the required number of queries is not reached:\n",
    "      - We randomly select an observation (row) from the synthetic dataset.\n",
    "      - We randomly pick a combination of columns within this observation.\n",
    "      - We construct a query incorporating the values of that observation in those columns, for instance `height_cm == 192 AND nationality_name == Spain`.\n",
    "      - We check if the generated query uniquely identifies only one observation in the synthetic dataset (singling-out query).\n",
    "\n",
    "2. **Validation on Real Dataset**:\n",
    "   - We test if the generated attacks are effective on the real dataset, that is we check if the query identifies a unique observation in the real dataset.\n",
    "   - If the attack is successful, indicating a potential data leakage of sensitive information, the query is added to the set of effective queries.\n",
    "\n",
    "\n",
    "The `SinglingOutEvaluator` try to measure how much the synthetic data can help an attacker finding combination of attributes that singles out records in the training data. With the following code we evaluate the robustness of the synthetic data to `univariate` singling out attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed48aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the Univariate SinglingOutEvaluator\n",
    "n_attacks = 500\n",
    "evaluator_univ = SinglingOutEvaluator(ori=ori, syn=syn, control=control, n_attacks=n_attacks)\n",
    "\n",
    "try:\n",
    "    evaluator_univ.evaluate(mode='univariate')\n",
    "    risk = evaluator_univ.risk()\n",
    "\n",
    "except RuntimeError as ex: \n",
    "    print(f\"Singling out evaluation failed with {ex}. Please re-run this cell.\"\n",
    "          \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "          \"make the evaluation slower.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f73d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(evaluator_univ.results())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f19b27",
   "metadata": {},
   "source": [
    "The `SinglingOutEvaluator` can also attack the dataset using predicates which are combining different attributes. These are the so called `multivariate` predicates. The number of attributes used in the attacker queries via the `n_cols` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f50db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the Multivariate SinglingOutEvaluator\n",
    "n_attacks = 400\n",
    "n_cols = 2\n",
    "\n",
    "evaluator_multiv = SinglingOutEvaluator(ori=ori, syn=syn, control=control, n_attacks=n_attacks, n_cols=n_cols)\n",
    "\n",
    "try:\n",
    "    evaluator_multiv.evaluate(mode='multivariate')\n",
    "    risk = evaluator_multiv.risk()\n",
    "\n",
    "except RuntimeError as ex: \n",
    "    print(f\"Singling out evaluation failed with {ex}. Please re-run this cell.\"\n",
    "          \"For more stable results increase `n_attacks`. Note that this will \"\n",
    "          \"make the evaluation slower.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2aaec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(evaluator_multiv.results())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b5fde8",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è The danger is real ‚ö†Ô∏è\n",
    "\n",
    "The singling out attack has allowed us to pinpoint specific queries that uniquely identify observations in the real dataset. This means that not only can we identify the attribute (or combination of attributes) that facilitated this identification, but we can potentially access all private data associated with these observations.\n",
    "\n",
    "Let's consider both the univariate and multivariate cases by accessing the `._queries` attribute of the evaluator to print the successful queries during the attack. By doing so, we can identify the initial observations, gaining access to sensitive information such as the player's salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd9b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_queries = evaluator_univ._queries\n",
    "print(\"Successful Univariate Queries:\", univ_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda09c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "df_name[(df_name['age'] == 54) | (df_name['height_cm'] == 156)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda4636",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiv_queries = evaluator_multiv._queries\n",
    "print(\"Successful Multivariate Queries:\", multiv_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ec3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "df_name[(df_name['club_name'] == 'FC Barcelona') & (df_name['age'] >= 34)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee90b2a8",
   "metadata": {},
   "source": [
    "## `Linkability Risk` ü™¢\n",
    "\n",
    "Linkability is the possibility of linking together two or more records (either in the same dataset or in different ones) belonging to the same individual or group of individuals: it can be used for de-anonymization. Due to statistical similarities between the generated data and the original data, linkability risks may still exist in synthetic datasets.\n",
    "\n",
    "üå≥ What happens under the hood? As described above, let's assume the attacker has access to datasets A and B, which each contain, among others, certain columns from the real dataset. The attacks are translated into code using two matrices of dimensions (n_attacks, n_neighbors), corresponding to datasets **A** and **B** respectively.\n",
    "\n",
    "1. **Generation of the attacks**:\n",
    "\n",
    "    - **Baseline Attack**: in the naive approach, nearest neighbors' indices are randomly chosen, meaning that both matrices are populated with random indices of observations from the synthetic dataset.\n",
    "\n",
    "    - **Main Attack & Control Attack**: For each row in each of the matrices, there corresponds an attack targeting an observation from the real dataset (randomly selected, but the same real observations for both **A** and **B**). For each attack (thus for each row), there are `n_neighbors` indices of observations from the synthetic dataset, indicating the nearest neighbors of the real observation in the synthetic dataset.\n",
    "\n",
    "2. **Evaluation of Attack Success**: If the intersection of indices from the corresponding rows in both matrices is non-empty, it indicates a successful link. Specifically, a synthetic sample that links the same real observation in both datasets **A** and **B** has been identified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4426ac16",
   "metadata": {},
   "source": [
    "### Linkability Attack Visualization\n",
    "\n",
    "**General Framework**: The plot consists of 3 rows and 2 columns, representing two datasets, **A** and **B**. The actions occur simultaneously and identically in both columns.\n",
    "\n",
    "- ***First Row***: We visualize **synthetic data** points in a 2D space. Each point is assigned a different color based on the total number of points (üü°üü¢üîµ).\n",
    "\n",
    "- ***Second Row***: We locate the **observation from the original dataset** (üî¥) intended for the linking attack. Additionally, we identify its **nearest neighbors** within the synthetic dataset.\n",
    "\n",
    "- ***Third Row***: We focus on identifying **common nearest neighbors** within the datasets A and B for the observation chosen in the second row. Visually, this involves checking if there are nearest neighbors with the same color in both datasets. \n",
    "\n",
    "<img src=\"./link_attack.png\" width=\"1600\" height=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00208da",
   "metadata": {},
   "source": [
    "The `LinkabilityEvaluator` allows one to know how much the synthetic data will help an adversary who tries to link two other datasets based on a subset of attributes. For example, suppose that the adversary finds dataset **A** containing, among other fields, information about the `height_cm`, `weight_kg` and `nationality_name` of FIFA football players, and dataset **B** containing some game-related information (`position` and `club_name`, for example). \n",
    "\n",
    "Can the attacker use the synthetic dataset to link these two datasets? \n",
    "To run the this attack, one needs to specify which columns of auxiliary information are available to the attacker, and how they are distributed between the two datasets **A** and **B**. This is done using the `aux_cols` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f056f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the LinkabilityEvaluator\n",
    "n_attacks = 2000\n",
    "aux_cols = [['height_cm', 'weight_kg', 'nationality_name'],\n",
    "            ['overall', 'age', 'club_name']]\n",
    "\n",
    "n_neighbors = 10\n",
    "\n",
    "evaluator = LinkabilityEvaluator(ori=ori, syn=syn, control=control,\n",
    "                                 n_attacks=n_attacks, aux_cols=aux_cols, n_neighbors=n_neighbors)\n",
    "\n",
    "evaluator.evaluate(n_jobs=-1)  # n_jobs follow joblib convention. -1 = all cores, -2 = all execept one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(evaluator.results())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15683429",
   "metadata": {},
   "source": [
    "### Unmasking Connections Across Datasets\n",
    "\n",
    "Let's try on our own and test the real danger of a Linkability Attack! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128b5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS \n",
    "\n",
    "from anonymeter.neighbors.mixed_types_kneighbors import MixedTypeKNeighbors\n",
    "from typing import cast, Dict, Set\n",
    "\n",
    "def _find_nn(syn: pd.DataFrame, ori: pd.DataFrame, n_jobs: int, n_neighbors: int) -> np.ndarray:\n",
    "    nn = MixedTypeKNeighbors(n_jobs=n_jobs, n_neighbors=n_neighbors)\n",
    "\n",
    "    if syn.ndim == 1:\n",
    "        syn = syn.to_frame()\n",
    "\n",
    "    if ori.ndim == 1:\n",
    "        ori = ori.to_frame()\n",
    "\n",
    "    nn.fit(syn)\n",
    "\n",
    "    return cast(np.ndarray, nn.kneighbors(ori, return_distance=False))\n",
    "\n",
    "def find_links(idx_0, idx_1, n_neighbors: int) -> Dict[int, Set[int]]:\n",
    "    \"\"\"Return synthetic records that link originals in the split datasets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_neighbors : int\n",
    "        Number of neighbors considered for the link search.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[int, Set[int]]\n",
    "        Dictionary mapping the index of the linking synthetic record\n",
    "        to the index of the linked original record.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    links = {}\n",
    "    for ii, (row0, row1) in enumerate(zip(idx_0, idx_1)):\n",
    "        joined = set(row0[:n_neighbors]) & set(row1[:n_neighbors])\n",
    "        if len(joined) > 0:\n",
    "            links[ii] = joined\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c0eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the LinkabilityEvaluator\n",
    "aux_cols = [['height_cm', 'weight_kg', 'nationality_name'],\n",
    "            ['overall', 'age', 'club_name']]\n",
    "n_neighbors = 10\n",
    "\n",
    "np.random.seed(42)\n",
    "targets = ori.sample(1000)\n",
    "\n",
    "A, B = targets[aux_cols[0]], targets[aux_cols[1]]\n",
    "syn_A, syn_B = syn[aux_cols[0]], syn[aux_cols[1]]\n",
    "\n",
    "idx_a = _find_nn(syn=syn_A, ori=A, n_neighbors=5, n_jobs=-1)\n",
    "idx_b = _find_nn(syn=syn_B, ori=B, n_neighbors=5, n_jobs=-1)\n",
    "\n",
    "links = find_links(idx_0=idx_a, idx_1=idx_b, n_neighbors=n_neighbors)\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9872a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original (partial) observations that have been linked\n",
    "AB = pd.concat([A.iloc[list(links.keys())],\n",
    "                B.iloc[list(links.keys())],],\n",
    "                axis=1,\n",
    "                keys=['A', 'B'])\n",
    "AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd140a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic linking observations\n",
    "vals = [list(i)[0] for i in links.values()]\n",
    "syn.iloc[vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f53d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = targets.iloc[list(links.keys())].index\n",
    "df_name.iloc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c51e41",
   "metadata": {},
   "source": [
    "### `Inference Risk` üéØ\n",
    "\n",
    "Inference happens when an attacker can confidently guess (infer) the value of an unknown attribute of the original data record.\n",
    "\n",
    "`Anonymeter` quantifies the inference risk by measuring the success of an attacker that tries to discover the value of some secret attribute for a set of target records on which some auxiliary knowledge is available.\n",
    "\n",
    "üå≥ What happens under the hood? We sample `n_attacks` observations from the original dataset. Considering all the columns in the dataset (real or synthetic, as the columns are the same), some are chosen as regressors, while one is selected as the target (identified as `secret`).\n",
    "\n",
    "1. **Generation of the attacks**:\n",
    "\n",
    "    - **Baseline Attack**: In this attack, `n_attacks` values of the `secret` column are randomly selected from the synthetic dataset and used as guesses for inference on the real dataset.\n",
    "\n",
    "    - **Main and Control Attacks**: Given the previously selected real sample, the nearest neighbor within the synthetic dataset is identified, and its `secret` attribute is used as an inference guess.\n",
    "\n",
    "2. **Evaluation of Attack Success**: The evaluation of the attack is quite intuitive: a guess is considered correct if:\n",
    "    - in the case of a categorical variable: the class is correct\n",
    "    - in the case of a numerical variable: the relative difference between the predicted and actual values is below a tolerance threshold (5%)\n",
    "\n",
    "\n",
    "Similar to the case of the Linkability Risk, the main parameter here is `aux_cols` which specify what the attacker knows about its target, i.e. which columns are known to the attacker. By selecting the `secret` column, one can identify which attributes, alone or in combinations, exhibit the largest risks and thereby expose a lot of information on the original data.\n",
    "\n",
    "In the following snippet we will measure the inference risk for each column individually, using all the other columns as auxiliary information to model a very knowledgeable attacker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ori.columns\n",
    "\n",
    "# Parameters for InferenceEvaluator\n",
    "n_attacks = 1000\n",
    "\n",
    "secret = 'wage_eur'\n",
    "aux_cols = [col for col in columns if col != secret]\n",
    "\n",
    "evaluator = InferenceEvaluator(ori=ori, syn=syn, control=control,\n",
    "                                   aux_cols=aux_cols, secret=secret, n_attacks=n_attacks)\n",
    "evaluator.evaluate(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da16306",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Inference attack for the variable \", secret)\n",
    "print_results(evaluator.results())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb9c87a",
   "metadata": {},
   "source": [
    "## What about `Differential Privacy`?\n",
    "\n",
    "### Differential Privacy in a Nutshell ü•ú\n",
    "\n",
    "Differential privacy is a framework for analyzing the privacy guarantees provided by data analysis algorithms. At its core, it aims to ensure that the **inclusion or exclusion of any individual's data from a dataset does not significantly affect the outcome of the analysis**, thus protecting the privacy of individuals in the dataset.\n",
    "This means that an observer should not be able to determine whether a specific individual's data is included in the dataset or not. This property helps prevent the leakage of sensitive information about individuals from the dataset.\n",
    "\n",
    "<img src=\"./diff_privacy.png\" width=\"900\" height=\"500\">\n",
    "\n",
    "\n",
    "The **privacy budget** is a crucial concept in differential privacy. It represents the maximum amount of privacy loss that a system can tolerate over multiple analyses or queries of the dataset. A higher privacy budget means that more privacy loss is allowed, increasing the risk of potential privacy breaches. Conversely, a lower privacy budget imposes stricter privacy guarantees, reducing the risk of privacy leakage but potentially limiting the utility of the data for analysis.\n",
    "\n",
    "\n",
    "As we approach the conclusion of the workshop, some key questions remains unanswered: \n",
    " \n",
    "- Are the guarantees provided by DP **truly effective** in safeguarding a dataset against attacks implemented by `anonymeter`?\n",
    "- Does the introduction of **noise** during the generation of synthetic data effectively protect the original data? \n",
    "\n",
    "Essentially, we are questioning whether there is a **tangible privacy gain at the expense of a natural reduction in utility**.\n",
    "\n",
    "If so, prioritizing methods incorporating Differential Privacy in data generation would make sense. Otherwise, it might be reasonable to favor standard methods.\n",
    "\n",
    "Let's re-run the three attacks on each of the synthetic datasets and save the results for subsequent visualization.\n",
    "\n",
    "‚è≥ **Since the execution of this cell might take a little time, feel free to address any questions, doubts, or curiosities you may have!** ‚è≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee127f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_datasets = [df_gaussian, df_privbayes, df_ctgan, df_dpctgan]\n",
    "model_names = ['GaussianCopula', 'PrivBayes', 'CTGAN', 'DPCTGAN']\n",
    "\n",
    "# Parameters\n",
    "n_attacks_single = 500\n",
    "n_cols = 2\n",
    "\n",
    "n_attacks_link = 1000\n",
    "aux_cols_link = [['height_cm', 'weight_kg', 'nationality_name'], ['overall', 'age', 'club_name']]\n",
    "n_neighbors = 8\n",
    "\n",
    "n_attacks_infer = 2000\n",
    "columns = ori.columns\n",
    "secret = 'wage_eur'\n",
    "aux_cols_infer = [col for col in columns if col != secret]\n",
    "\n",
    "results = {'Singling Out' : {},\n",
    "           'Linkability' : {},\n",
    "           'Inference' : {}}\n",
    "\n",
    "for i, syn in enumerate(synthetic_datasets):\n",
    "\n",
    "    # Multivariate Singling-Out\n",
    "    evaluator_single = SinglingOutEvaluator(ori=ori, syn=syn, control=control, n_attacks=n_attacks_single, n_cols=n_cols)\n",
    "    evaluator_single.evaluate(mode='multivariate')\n",
    "    results['Singling Out'][model_names[i]] = [evaluator_single.results().attack_rate, evaluator_single.results().control_rate]\n",
    "    \n",
    "    # Linkability\n",
    "    evaluator_link = LinkabilityEvaluator(ori=ori, syn=syn, control=control, n_attacks=n_attacks_link, aux_cols=aux_cols_link, n_neighbors=n_neighbors)\n",
    "    evaluator_link.evaluate(n_jobs=-1)  # n_jobs follow joblib convention. -1 = all cores, -2 = all execept one\n",
    "    results['Linkability'][model_names[i]] = [evaluator_link.results().attack_rate, evaluator_link.results().control_rate]\n",
    "\n",
    "    # Inference\n",
    "    evaluator_infer = InferenceEvaluator(ori=ori, syn=syn, control=control, aux_cols=aux_cols_infer, secret=secret, n_attacks=n_attacks_infer)\n",
    "    evaluator_infer.evaluate(n_jobs=-1)\n",
    "    results['Inference'][model_names[i]] = [evaluator_infer.results().attack_rate, evaluator_infer.results().control_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2fb8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTION\n",
    "def print_comparison(results, model_names):\n",
    "    \n",
    "    values = []\n",
    "    errors = []\n",
    "\n",
    "    for i, attack in enumerate(results.keys()):\n",
    "        for j, model in enumerate(model_names):\n",
    "            values.append(results[attack][model][0].value)\n",
    "            errors.append(results[attack][model][0].error)\n",
    "        \n",
    "        data = results[attack]\n",
    "\n",
    "        values_main = [data[model][0].value for model in model_names]\n",
    "        errors_main = [data[model][0].error for model in model_names]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Attack': ['Singling Out'] * len(model_names) + ['Linkability'] * len(model_names) + ['Inference'] * len(model_names),\n",
    "        'Model': len(results) * model_names,\n",
    "        'Value': values,\n",
    "        'Lower CI': [values[k]-errors[k] for k in range(len(values))],\n",
    "        'Upper CI': [values[k]+errors[k] for k in range(len(values))]\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    barplot = sns.barplot(x='Attack', y='Value', hue='Model', data=df,)\n",
    "    bar_centers = [patch.get_x() + patch.get_width() / 2 for patch in barplot.patches]\n",
    "    plt.errorbar(x=sorted(bar_centers[:df.shape[0]]), y=values, yerr=errors, fmt='none', color='k', capsize=5)\n",
    "\n",
    "    plt.xlabel('Attack Type')\n",
    "    plt.ylabel('Succes Rate')\n",
    "    plt.title('Success Rates of Attacks and 95% CIs')\n",
    "    plt.legend(title='Model', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8a89b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_comparison(results, model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62f3f84",
   "metadata": {},
   "source": [
    "#### Do you want to know something more about differential privacy? \n",
    "\n",
    "Here's what you need to get started:\n",
    "\n",
    "- *Where everything started:* \n",
    "    - Dwork et al. [Calibrating Noise to Sensitivity in Private Data Analysis](https://link.springer.com/chapter/10.1007/11681878_14)\n",
    "    - Dwork [Differential Privacy](https://link.springer.com/chapter/10.1007/11787006_1)\n",
    "    \n",
    "\n",
    "- *Œµ-differential privacy:* Dwork, C. (2006). [Differential Privacy](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/dwork.pdf). In ICALP, volume 2.\n",
    "\n",
    "\n",
    "- *Educational materials:* [Harvard Privacy Tools - Courses & Educational Materials](https://privacytools.seas.harvard.edu/courses-educational-materials)\n",
    "\n",
    "\n",
    "- *Clearly written Blog (with reference to the foundational work of DP):* [Common Misconceptions About Differential Privacy](https://gretel.ai/blog/common-misconceptions-about-differential-privacy)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
